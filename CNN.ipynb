{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2c3412a4-039b-4229-9387-9321169f16eb",
    "_uuid": "8def9627e9d48b26de3159fc9a2ec38e854ab16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist_test.csv\n",
      "fashion-mnist_train.csv\n",
      "t10k-images-idx3-ubyte\n",
      "t10k-labels-idx1-ubyte\n",
      "train-images-idx3-ubyte\n",
      "train-labels-idx1-ubyte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"data\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c56a778-ba24-4d51-a89d-a16b7da3f47c",
    "_uuid": "a04a2a1268aabc722a26e5aada6921afd8b19e2f"
   },
   "source": [
    "# Brief Info\n",
    "\n",
    "In this work, we will train a CNN classifier using Keras with the guidelines described in [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python).\n",
    "\n",
    "Our strategy will be using 20% of the train data (12000 data rows) as a validation set to optimize the classifier, while keeping test data to finally evaluate the accuracy of the model on the data it has never seen.\n",
    "\n",
    "#### Note\n",
    "Since I was not sure if the data was already shuffled, I didn't pass `validation_split=0.2` to _fit()_ and instead explicitly shuffled and split the validation data, as `validation_split` [would](https://keras.io/getting-started/faq/#how-is-the-validation-split-computed) use last 20% of the data in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
    "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "#Here we split validation data to optimiza classifier during training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "#Test data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0599166d-b975-4c88-8b91-071a8f4fb0cd",
    "_uuid": "0e9db73157e2c0e481bf3d73892d8d29263aa56f"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "4543df54-7373-49f8-a23a-6d8062eefe38",
    "_uuid": "9de535d8a446b7168ac3790445610425527c8a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9d072ca-23e7-4608-a9d8-dc818715d6e3",
    "_uuid": "1e85d4b1d5fb567f2aad6bd82da969629e585f14"
   },
   "source": [
    "### Training\n",
    "Let's `fit()`! Note that `fit()` will return a _History_ object which we can use to plot training vs. validation accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f24bf149-70e5-43f2-8574-117606493c85",
    "_uuid": "71b754f661ab2bba5e0d2c280d033a57300ef7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 65s 1ms/step - loss: 0.8476 - acc: 0.6865 - val_loss: 0.5037 - val_acc: 0.8171\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.5233 - acc: 0.8046 - val_loss: 0.4124 - val_acc: 0.8488\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.4492 - acc: 0.8343 - val_loss: 0.3712 - val_acc: 0.8617\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.4024 - acc: 0.8551 - val_loss: 0.3370 - val_acc: 0.8758\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.3712 - acc: 0.8642 - val_loss: 0.3126 - val_acc: 0.8850\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.3471 - acc: 0.8739 - val_loss: 0.2937 - val_acc: 0.8937\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 64s 1ms/step - loss: 0.3314 - acc: 0.8777 - val_loss: 0.2926 - val_acc: 0.8927\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 65s 1ms/step - loss: 0.3192 - acc: 0.8817 - val_loss: 0.2855 - val_acc: 0.8953\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.3077 - acc: 0.8882 - val_loss: 0.2668 - val_acc: 0.9019\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.2991 - acc: 0.8897 - val_loss: 0.2624 - val_acc: 0.9037\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2880 - acc: 0.8933 - val_loss: 0.2646 - val_acc: 0.9002\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2831 - acc: 0.8952 - val_loss: 0.2653 - val_acc: 0.9025\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2784 - acc: 0.8967 - val_loss: 0.2573 - val_acc: 0.9053\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2725 - acc: 0.8997 - val_loss: 0.2503 - val_acc: 0.9055\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.2660 - acc: 0.9019 - val_loss: 0.2457 - val_acc: 0.9078\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.2623 - acc: 0.9043 - val_loss: 0.2429 - val_acc: 0.9097\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.2577 - acc: 0.9053 - val_loss: 0.2424 - val_acc: 0.9094\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.2523 - acc: 0.9064 - val_loss: 0.2397 - val_acc: 0.9119\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.2455 - acc: 0.9086 - val_loss: 0.2383 - val_acc: 0.9122\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.2451 - acc: 0.9111 - val_loss: 0.2426 - val_acc: 0.9081\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.2406 - acc: 0.9103 - val_loss: 0.2332 - val_acc: 0.9122\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.2358 - acc: 0.9119 - val_loss: 0.2293 - val_acc: 0.9154\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.2335 - acc: 0.9130 - val_loss: 0.2319 - val_acc: 0.9131\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2319 - acc: 0.9124 - val_loss: 0.2283 - val_acc: 0.9155\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.2238 - acc: 0.9167 - val_loss: 0.2315 - val_acc: 0.9132\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2234 - acc: 0.9159 - val_loss: 0.2281 - val_acc: 0.9158\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2243 - acc: 0.9164 - val_loss: 0.2255 - val_acc: 0.9162\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.2209 - acc: 0.9187 - val_loss: 0.2301 - val_acc: 0.9140\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 64s 1ms/step - loss: 0.2198 - acc: 0.9175 - val_loss: 0.2228 - val_acc: 0.9180\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.2143 - acc: 0.9181 - val_loss: 0.2287 - val_acc: 0.9131\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2139 - acc: 0.9208 - val_loss: 0.2232 - val_acc: 0.9187\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2111 - acc: 0.9207 - val_loss: 0.2286 - val_acc: 0.9169\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.2104 - acc: 0.9221 - val_loss: 0.2232 - val_acc: 0.9159\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.2025 - acc: 0.9233 - val_loss: 0.2205 - val_acc: 0.9181\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2055 - acc: 0.9234 - val_loss: 0.2230 - val_acc: 0.9163\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2042 - acc: 0.9230 - val_loss: 0.2247 - val_acc: 0.9176\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2057 - acc: 0.9229 - val_loss: 0.2206 - val_acc: 0.9185\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.2010 - acc: 0.9243 - val_loss: 0.2287 - val_acc: 0.9141\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.2000 - acc: 0.9245 - val_loss: 0.2209 - val_acc: 0.9193\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.2001 - acc: 0.9246 - val_loss: 0.2208 - val_acc: 0.9190\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 56s 1ms/step - loss: 0.1970 - acc: 0.9253 - val_loss: 0.2204 - val_acc: 0.9213\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.1990 - acc: 0.9268 - val_loss: 0.2157 - val_acc: 0.9203\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.1934 - acc: 0.9281 - val_loss: 0.2202 - val_acc: 0.9208\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.1934 - acc: 0.9263 - val_loss: 0.2204 - val_acc: 0.9198\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.1930 - acc: 0.9260 - val_loss: 0.2131 - val_acc: 0.9212\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.1871 - acc: 0.9290 - val_loss: 0.2247 - val_acc: 0.9164\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.1914 - acc: 0.9269 - val_loss: 0.2197 - val_acc: 0.9188\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.1886 - acc: 0.9289 - val_loss: 0.2136 - val_acc: 0.9218\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 65s 1ms/step - loss: 0.1861 - acc: 0.9286 - val_loss: 0.2156 - val_acc: 0.9234\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.1886 - acc: 0.9289 - val_loss: 0.2179 - val_acc: 0.9206\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "model.save(\"cnn_on_fashion_minst.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4b6cb78-1ef8-46ba-b72d-49a49c81bff0",
    "_uuid": "48787728c57ad402547540b5d528aabbd8b20c0d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f860c207-af4d-4c32-b4d2-4ea2d39902fe",
    "_uuid": "d18bc5dd0ec23cda8ea5ad846b9877704f484951"
   },
   "source": [
    "### Results\n",
    "It turns out our classifier does better then the best baseline reported [here](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/), which is an SVM classifier with mean accuracy of 0.897.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "00dc5434-a008-490d-bb89-a394cf95c4bc",
    "_uuid": "adbb96b3d90dcab280f06341a8483f246f583a03"
   },
   "source": [
    "\n",
    "Let's plot training and validation accuracy as well as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "324c3a68-6381-4a39-a5a1-8fac766150c0",
    "_uuid": "042117c73a10d7cbda6bc42ab60f9b0407cdf2c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1311601b-9a53-4e59-adcd-4365c811f85e",
    "_uuid": "28e5331842de7baaffb3a1e74f6a4c03e140759a"
   },
   "source": [
    "### Classification Report\n",
    "We can summarize the performance of our classifier as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "721514ef-520b-42a2-9d57-2f82fbae8393",
    "_uuid": "0275d1189e6425353537fa3ebe5d97d7b6759551",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "\n",
    "#get the indices to be plotted\n",
    "y_true = data_test.iloc[:, 0]\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a150e22-1b7f-4dec-abf9-5e986a712349",
    "_uuid": "0376ca4434f36045a6729529032f4e8072f25d2d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc36576e-c630-4581-89fe-3bed02c378bb",
    "_uuid": "2863d680886cc22a2e6f11270b411e435410adaf"
   },
   "source": [
    "It's apparent that our classifier is underperforming for class 6 in terms of both precision and recall. For class 2, classifier is slightly lacking precision whereas it is slightly lacking recall (i.e. missed) for class 4.\n",
    "\n",
    "Perhaps we would gain more insight after visualizing the correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "866ef2af-d4e1-4697-bf87-9dcaa7cba363",
    "_uuid": "6a78901cefbe9a3bdf89cc1d22ee910970cfaf93"
   },
   "source": [
    "Here is a subset of correctly predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5a33d457-ff62-4e32-81d7-89a6cdc1106d",
    "_uuid": "d8148b3557ac27d216e0137bbeae06379c829779",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_true[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9726e897-4d69-44d5-a1d5-358d316b5141",
    "_uuid": "a22f4456fa1c09e609db1a6c0e8eb1438087fa91"
   },
   "source": [
    "And here is a subset of incorrectly predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "803d7c3f-2099-420d-9612-dcf617d6cbe0",
    "_uuid": "fa4d360a4e77bd3d83490065351860b1d9f58f8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_true[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd66b1b1-db6f-47e4-aa2e-3ce516979fa3",
    "_uuid": "89881c6e4d1169ac543b5de992832d9e423dfdde"
   },
   "source": [
    "It looks like diversity of the similar patterns present on multiple classes effect the performance of the classifier although CNN is a robust architechture. A jacket, a shirt, and a long-sleeve blouse has similar patterns: long sleeves (or not!), buttons (or not!), and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2d4e41bf-07a3-4aa1-a89b-b2b1c3c19aaf",
    "_uuid": "04ce0bbb3160fe7750432a20a912308598cfc804"
   },
   "source": [
    "#### What did the network learn?\n",
    "\n",
    "The snippets are taken from _Chollet, F (2017)_. The idea is the give an input data and visualize the activations of the conv layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f9993fe-e0b8-4850-84aa-92499afc9b60",
    "_uuid": "382e3bd0030f728700ce0a6c3e2e9442d641c6e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_im = X_train[13]\n",
    "plt.imshow(test_im.reshape(28,28), cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e836de6d-4378-40ce-a3b3-f01269788479",
    "_uuid": "ca607572942ddc3080e4b8b74d6bc47779fe66ae"
   },
   "source": [
    "Let's see the activation of the 2nd channel of the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3952d67-8187-4a8e-9e82-8bef6482e04c",
    "_uuid": "15a26cf258d1fd6152d201258538ce829bed1ccc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(input=model.input, output=layer_outputs)\n",
    "activations = activation_model.predict(test_im.reshape(1,28,28,1))\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6081331c-280d-442f-afc2-edf3c54b02bd",
    "_uuid": "1969b931bf29620f2546454de5133e3b2df8080f"
   },
   "source": [
    "Let's plot the activations of the other conv layers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9e0c8cc-6b25-4043-8f7c-d8b95ec27923",
    "_uuid": "0ac1180af62085842f361291ff716bdb3935c98a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[:-1]:\n",
    "    if isinstance(layer, Conv2D):\n",
    "        layer_names.append(layer.name)\n",
    "images_per_row = 16\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    size = layer_activation.shape[1]\n",
    "    n_cols = n_features / images_per_row\n",
    "    n_cols = int(n_cols)\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='bone')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
